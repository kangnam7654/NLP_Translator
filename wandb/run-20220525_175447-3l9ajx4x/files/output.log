
Sanity Checking: 0it [00:00, ?it/s]
Using 16bit native Automatic Mixed Precision (AMP)
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
D:\conda\envs\NLP_Translator_39\lib\site-packages\pytorch_lightning\callbacks\model_checkpoint.py:611: UserWarning: Checkpoint directory D:\project\kang_bart\ckpt exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name  | Type                         | Params
-------------------------------------------------------
0 | model | BartForConditionalGeneration | 125 M
-------------------------------------------------------
125 M     Trainable params
0         Non-trainable params
125 M     Total params





































































































































































































































































































































































































